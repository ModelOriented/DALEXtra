---
output: github_document
---

```{r setup, include=FALSE, message=FALSE, warning=TRUE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# DALEXtra <img src="man/figures/logo.png" align="right" width="150"/>

[![Build Status](https://travis-ci.org/ModelOriented/DALEXtra.svg?branch=master)](https://travis-ci.org/ModelOriented/DALEXtra)
[![Coverage
Status](https://img.shields.io/codecov/c/github/ModelOriented/DALEXtra/master.svg)](https://codecov.io/github/ModelOriented/DALEXtra?branch=master)
[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/DALEXtra)](https://cran.r-project.org/package=DALEXtra)

## Overview

The `DALEXtra` package is an extension pack for [DALEX](https://modeloriented.github.io/DALEX) package.
This package provides easy to use connectors for models created with scikitlearn, keras, H2O, mljar and mlr.


## Installation

```
# Install the development version from GitHub:

# it is recommended to install latest version of DALEX from GitHub
devtools::install_github("ModelOriented/DALEX")
# install.packages("devtools")
devtools::install_github("ModelOriented/DALEXtra")
```

Package `reticulate` will be downloaded along with `DALEXtra` but if you seek for it's latest version it can be downloaded here

```
devtools::install_github("rstudio/reticulate")
```

Other packages useful with explanations.

```
devtools::install_github("ModelOriented/ingredients")
devtools::install_github("ModelOriented/iBreakDown")
devtools::install_github("ModelOriented/shapper")
devtools::install_github("ModelOriented/auditor")
```

Above packages can be used along with `explain` object to create explanations (ingredients, iBreakDown, shapper) or audit our model (audiotr).


## How to setup Anaconda

In order to be able to use some features associated with `DALEXtra`, Anaconda in needed. The easiest way to get it, is visiting 
[Anaconda website](https://www.anaconda.com/distribution). And choosing proper OS as it stands in the following picture.
![](https://raw.githubusercontent.com/ModelOriented/DALEXtra/master/README_files/figure-gfm/anaconda1.png) There is no big difference bewtween Python versions when downloading Anaconda. You can always create virtual environment with any version of Python no matter which version was downloaded first.

### Windows 

Crucial thing is adding conda to PATH environment variable when using Windows. You can do it during installation, by marking this checkbox.

![](https://raw.githubusercontent.com/ModelOriented/DALEXtra/master/README_files/figure-gfm/anaconda2.png)

or, if conda is already installed, by following [those instructions](https://stackoverflow.com/a/44597801/9717584).

### Unix

While using unix-like OS, adding conda to PATH is not required.

## Demo

Here we will present short use case for our package and its compatibility with Python

### Loading data

First we need provide the data, explainer is useless without them. Thing is Python object does not store training data so always have to provide dataset. Feel free to use those attached to `DALEX` package or those stored in `DALEXtra` files. 

```{r}
titanic_test <- read.csv(system.file("extdata", "titanic_test.csv", package = "DALEXtra"))
```
Keep in mind that dataframe includes target variable (18th column) and scikit-learn models cannot work with it.

### Creating explainer

Creating exlainer from scikit-learn Python model is very simple thanks to `DALEXtra`. The only thing you need to provide is path to pickle and, if necessary, something that lets recognize Python environment. It may be a .yml file with packages specification, name of existing conda environment or path to Python virtual environment. Execution of `scikitlearn_explain` only with .pkl file and data will cause usage of default Python.

```{r}
library(DALEXtra)
explainer <- explain_scikitlearn(system.file("extdata", "scikitlearn.pkl", package = "DALEXtra"),
yml = system.file("extdata", "testing_environment.yml", package = "DALEXtra"), 
data = titanic_test[,1:17], y = titanic_test$survived)
```

### Creating explanations
Now with explainer ready we can use any of [DrWhy.ai](https://github.com/ModelOriented/DrWhy/blob/master/README.md) universe tools to make explanations. Here is a small demo.
```{r}
library(DALEX)
plot(model_performance(explainer))
library(ingredients)
plot(feature_importance(explainer))
describe(feature_importance(explainer))
library(iBreakDown)
plot(break_down(explainer, titanic_test[2,1:17]))
describe(break_down(explainer, titanic_test[2,1:17]))
library(shapper)
plot(shap(explainer, titanic_test[2,1:17]))
library(auditor)
eval <- model_evaluation(explainer)
plot_roc(eval)

# Predictions with newdata
predict(explainer, titanic_test[1:10, 1:17])
```


## Acknowledgments

Work on this package was financially supported by the 'NCN Opus grant 2016/21/B/ST6/02176'.
    
